\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\citation{hsu2020recommending}
\citation{ferreira2018online}
\citation{murphy2005experimental}
\citation{offer2021adaptive}
\citation{satyal2018ab}
\citation{bouneffouf2020survey}
\citation{chapelle2011}
\citation{abeille2017linear}
\citation{lattimore2020bandit}
\babel@aux{nil}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{agrawal2013thompson}
\citation{abeille2017linear}
\citation{dimakopoulou2019balanced}
\citation{kim2021doubly}
\citation{huix2023tight}
\citation{abe1999associative}
\citation{auer2002using,dani2008stochastic,rusmevichientong2010linearly,chu2011contextual,abbasi2011improved}
\citation{agrawal2013thompson,abeille2017linear}
\citation{chapelle2011}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of regret bounds and assumptions on \texttt  {LinTS}}}{2}{table.1}\protected@file@percent }
\newlabel{tab:ts-regret-comparison}{{1}{2}{Comparison of regret bounds and assumptions on \texttt {LinTS}}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Literature}{2}{section.2}\protected@file@percent }
\newlabel{sec:related_works}{{2}{2}{}{section.2}{}}
\citation{lattimore2020bandit}
\citation{kim2021doubly}
\citation{bastani2021mostly}
\citation{kim2023double}
\citation{huix2023tight}
\citation{agrawal2017near}
\citation{zhu2020thompson}
\citation{bang2005doubly}
\citation{dimakopoulou2019balanced}
\citation{kim2019doubly}
\citation{kim2021doubly}
\citation{kim2023double}
\citation{kim2023squeeze}
\citation{hamidi2019worst}
\citation{kveton2021metats}
\citation{lai1985asymptotically}
\citation{riou2023matching}
\citation{buhlmann2011statistics}
\citation{smith1918standard,guttorp2009karl}
\citation{mockus2005bayesian}
\citation{kim2019doubly,kim2021doubly}
\@writefile{toc}{\contentsline {section}{\numberline {3}Linear Contextual Bandit Problem}{4}{section.3}\protected@file@percent }
\newlabel{sec:LinCB}{{3}{4}{}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Notations}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Problem Formulation}{4}{subsection.3.2}\protected@file@percent }
\citation{abbasi2011improved}
\citation{abbasi2011improved}
\citation{lattimore2020bandit}
\citation{kim2021doubly}
\citation{kim2023squeeze}
\citation{bishop1995training}
\citation{perturb20akveton}
\citation{kim2021doubly}
\@writefile{toc}{\contentsline {section}{\numberline {4}Augmenting Hypothetical Contexts for Linear Bandits}{5}{section.4}\protected@file@percent }
\newlabel{sec:augment}{{4}{5}{}{section.4}{}}
\newlabel{eq:ridge}{{1}{5}{}{equation.1}{}}
\newlabel{eq:DR_estimator}{{2}{5}{}{equation.2}{}}
\citation{smith1918standard}
\citation{guttorp2009karl}
\citation{soare2014best}
\citation{tao2018best}
\citation{kim2021doubly}
\@writefile{toc}{\contentsline {section}{\numberline {5}Proposed Method}{6}{section.5}\protected@file@percent }
\newlabel{sec:proposed_method}{{5}{6}{}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Design of Hypothetical Contexts}{6}{subsection.5.1}\protected@file@percent }
\newlabel{sec:hypo_contexts}{{5.1}{6}{}{subsection.5.1}{}}
\newlabel{eq:X_decomp}{{3}{7}{}{equation.3}{}}
\newlabel{eq:norm_bound}{{4}{7}{}{equation.4}{}}
\newlabel{lem:Hypo_dom}{{1}{7}{Hypothetical Gram Matrix Domination Lemma}{theorem.1}{}}
\newlabel{eq:Gram_1}{{5}{7}{}{equation.5}{}}
\citation{kim2021doubly}
\newlabel{lem:Hypo_equiv}{{2}{8}{Hypothetical Gram Matrix Equivalence Lemma}{theorem.2}{}}
\newlabel{eq:Gram_equiv_0}{{6}{8}{}{equation.6}{}}
\newlabel{eq:Gram_equiv_a_t_norm}{{7}{8}{}{equation.7}{}}
\newlabel{eq:Gram_equiv_1}{{8}{9}{}{equation.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Orthogonal Basis Augmentation}{10}{subsection.5.2}\protected@file@percent }
\newlabel{eq:h_t}{{9}{10}{}{equation.9}{}}
\newlabel{eq:A}{{10}{10}{}{equation.10}{}}
\newlabel{eq:T_1}{{11}{10}{}{equation.11}{}}
\newlabel{lem:tilde_equivlence}{{3}{10}{Gram matrix with hypothetical contexts}{theorem.3}{}}
\newlabel{eq:N}{{12}{10}{}{equation.12}{}}
\citation{kim2021doubly}
\newlabel{eq:new_contexts}{{13}{11}{}{equation.13}{}}
\newlabel{lem:Gram}{{4}{11}{Gram matrix with hypothetical contexts}{theorem.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}A Hypothetical Linear Contextual Bandit}{12}{subsection.5.3}\protected@file@percent }
\newlabel{sec:hypothetical_bandit}{{5.3}{12}{}{subsection.5.3}{}}
\newlabel{eq:pseudo_prob}{{14}{12}{}{equation.14}{}}
\newlabel{eq:impute}{{15}{12}{}{equation.15}{}}
\newlabel{eq:HDRY}{{16}{12}{}{equation.16}{}}
\newlabel{eq:Hypo_DR}{{17}{12}{}{equation.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Coupling the Hypothetical and Original Linear Contextual Bandits}{12}{subsection.5.4}\protected@file@percent }
\newlabel{sec:coupling}{{5.4}{12}{}{subsection.5.4}{}}
\citation{kim2021doubly}
\citation{xu2020upper}
\citation{kim2021doubly}
\citation{xu2020upper}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Flow diagram of the proposed coupling and resampling scheme}}{13}{figure.1}\protected@file@percent }
\newlabel{fig:process}{{1}{13}{Flow diagram of the proposed coupling and resampling scheme}{figure.1}{}}
\newlabel{eq:matching_event}{{18}{13}{}{equation.18}{}}
\citation{kim2021doubly}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Illustration of coupling success and failure during resampling for $N_{t}=2$ and $K=3$. By construction, $Z_{2,t}:=X_{a_{t},t}$ and $W_{2,t}:=Y_{a_{t},t}$. Gray cells indicate the selected actions.}}{14}{table.2}\protected@file@percent }
\newlabel{tab:coupling}{{2}{14}{Illustration of coupling success and failure during resampling for $N_{t}=2$ and $K=3$. By construction, $Z_{2,t}:=X_{a_{t},t}$ and $W_{2,t}:=Y_{a_{t},t}$. Gray cells indicate the selected actions}{table.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Candidate-Arm Sampler (\texttt  {CAS}) for Round $t$}}{14}{algorithm.1}\protected@file@percent }
\newlabel{alg:cas}{{1}{14}{}{algorithm.1}{}}
\newlabel{eq:CoY}{{19}{14}{}{equation.19}{}}
\newlabel{eq:A_estimator}{{20}{14}{}{equation.20}{}}
\newlabel{lem:coupling}{{5}{15}{A coupling inequality}{theorem.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Hypothetical Coupled Sample Augmented Thompson Sampling}{16}{subsection.5.5}\protected@file@percent }
\newlabel{sec:algorithm}{{5.5}{16}{}{subsection.5.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Hypothetical Coupled Sample Augmented Thompson Sampling (\texttt  {HCSA+TS})}}{17}{algorithm.2}\protected@file@percent }
\newlabel{alg:ATS}{{2}{17}{}{algorithm.2}{}}
\citation{lattimore2020bandit}
\citation{kim2021doubly}
\citation{kim2023squeeze}
\citation{huix2023tight}
\citation{kim2021doubly}
\citation{agrawal2013thompson}
\citation{abbasi2011improved}
\@writefile{toc}{\contentsline {section}{\numberline {6}Regret Analysis}{18}{section.6}\protected@file@percent }
\newlabel{sec:regret_analysis}{{6}{18}{}{section.6}{}}
\newlabel{thm:regret_bound}{{6}{18}{Regret Bound for \texttt {HCSA+TS}}{theorem.6}{}}
\newlabel{eq:regret_bound}{{21}{18}{Regret Bound for \texttt {HCSA+TS}}{equation.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}A Self-Normalized Bound for the Proposed Estimator}{18}{subsection.6.1}\protected@file@percent }
\newlabel{sec:self}{{6.1}{18}{}{subsection.6.1}{}}
\newlabel{lem:error_decomposition}{{7}{18}{A self-normalized bound of the HSA estimator}{theorem.7}{}}
\citation{abbasi2011improved}
\citation{kim2023squeeze}
\newlabel{thm:self}{{8}{19}{A Self-Normalized Bound for the HCSA Estimator}{theorem.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Low-Regret Arms with a High-Probability Guarantee}{19}{subsection.6.2}\protected@file@percent }
\newlabel{sec:low_regret_arms}{{6.2}{19}{}{subsection.6.2}{}}
\newlabel{eq:low_regret_set}{{22}{19}{}{equation.22}{}}
\citation{agrawal2013thompson}
\newlabel{lem:super_unsaturated_arms}{{9}{20}{High-Probability Selection of Low-Regret Arms}{theorem.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Maximal Elliptical Potential Bound}{20}{subsection.6.3}\protected@file@percent }
\newlabel{sec:max_elliptical}{{6.3}{20}{}{subsection.6.3}{}}
\newlabel{lem:elliptical}{{10}{20}{Maximal elliptical potential lemma}{theorem.10}{}}
\citation{kim2021doubly}
\citation{kim2023squeeze}
\citation{chu2011contextual}
\citation{kim2021doubly}
\@writefile{toc}{\contentsline {section}{\numberline {7}Experimental Results}{21}{section.7}\protected@file@percent }
\newlabel{sec:experiment}{{7}{21}{}{section.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Comparison of the regrets of the proposed \texttt  {HCSA+TS} algorithm with other benchmark methods. The lines represent the average, and the shaded areas indicate the standard deviation based on twenty experiments. The results demonstrate that the proposed \texttt  {HCSA+TS} effectively identifies the optimal arm using orthogonal regularization.}}{22}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Regret comparison ($d=10$, $K=20$)}}}{22}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Regret comparison ($d=30$, $K=20$)}}}{22}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Regret comparison ($d=10$, $K=30$)}}}{22}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Regret comparison ($d=30$, $K=30$)}}}{22}{figure.2}\protected@file@percent }
\newlabel{fig:comparison}{{2}{22}{Comparison of the regrets of the proposed \texttt {HCSA+TS} algorithm with other benchmark methods. The lines represent the average, and the shaded areas indicate the standard deviation based on twenty experiments. The results demonstrate that the proposed \texttt {HCSA+TS} effectively identifies the optimal arm using orthogonal regularization}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Comparison of the prediction error across all arms, calculated as $\DOTSB \sum@ \slimits@ _{i=1}^{K}\{X_{i,t}^{\top }(\setbox \z@ \hbox {\mathsurround \z@ $\textstyle \theta $}\mathaccent "0362{\theta }_{t}-\theta _{\star })\}^{2}$, for the proposed \texttt  {HCSA+TS} and other benchmark methods. The lines represent the averages, and the shaded areas indicate the standard deviations based on twenty experiments. The results demonstrate that the proposed estimator, enhanced with orthogonal augmentation, learns the reward more accurately than other estimators.}}{23}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Prediction error comparison ($d=10$, $K=20$)}}}{23}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Prediction error comparison ($d=30$, $K=20$)}}}{23}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Prediction error comparison ($d=10$, $K=30$)}}}{23}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Prediction error comparison ($d=30$, $K=30$)}}}{23}{figure.3}\protected@file@percent }
\newlabel{fig:prediction}{{3}{23}{Comparison of the prediction error across all arms, calculated as $\sum _{i=1}^{K}\{X_{i,t}^{\top }(\widehat {\theta }_{t}-\theta _{\star })\}^{2}$, for the proposed \texttt {HCSA+TS} and other benchmark methods. The lines represent the averages, and the shaded areas indicate the standard deviations based on twenty experiments. The results demonstrate that the proposed estimator, enhanced with orthogonal augmentation, learns the reward more accurately than other estimators}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{24}{section.8}\protected@file@percent }
\newlabel{sec:conclusion}{{8}{24}{}{section.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Missing Proofs}{24}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Proof of Lemma~\ref {lem:error_decomposition}}{24}{subsection.A.1}\protected@file@percent }
\newlabel{sec:error_decomposition_proof}{{A.1}{24}{}{subsection.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Proof of Theorem \ref {thm:self}}{25}{subsection.A.2}\protected@file@percent }
\newlabel{sec:tail_proof}{{A.2}{25}{}{subsection.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Probability Bounds for the Norms}{27}{subsection.A.3}\protected@file@percent }
\newlabel{lem:P_t_bound}{{11}{27}{}{theorem.11}{}}
\newlabel{lem:S_t_bound}{{12}{29}{}{theorem.12}{}}
\citation{abbasi2011improved}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Proof of Lemma~\ref {lem:super_unsaturated_arms}}{30}{subsection.A.4}\protected@file@percent }
\newlabel{sec:low_regret_proof}{{A.4}{30}{}{subsection.A.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5}Proof of Lemma~\ref {lem:elliptical}}{31}{subsection.A.5}\protected@file@percent }
\newlabel{sec:proof_elliptical}{{A.5}{31}{}{subsection.A.5}{}}
\citation{abbasi2011improved}
\citation{kim2025learning}
\citation{tropp2012user}
\@writefile{toc}{\contentsline {section}{\numberline {B}Technical Results}{32}{appendix.B}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Threshold for logarithmic inequality.}{32}{subsection.B.1}\protected@file@percent }
\newlabel{prop:logt}{{13}{32}{Threshold for logarithmic inequality Lemma C.6 in \citet {kim2025learning}}{theorem.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}A Matrix Concentration Inequality}{32}{subsection.B.2}\protected@file@percent }
\newlabel{lem:matrix_neg}{{14}{32}{Matrix concentration inequality}{theorem.14}{}}
\citation{tropp2015introduction}
\bibdata{ref}
\bibcite{abbasi2011improved}{{1}{2011}{{Abbasi-Yadkori et~al.}}{{Abbasi-Yadkori, P{\'a}l, and Szepesv{\'a}ri}}}
\bibcite{abe1999associative}{{2}{1999}{{Abe and Long}}{{}}}
\bibcite{abeille2017linear}{{3}{2017}{{Abeille et~al.}}{{Abeille, Lazaric, et~al.}}}
\bibcite{agrawal2013thompson}{{4}{2013}{{Agrawal and Goyal}}{{}}}
\bibcite{agrawal2017near}{{5}{2017}{{Agrawal and Goyal}}{{}}}
\bibcite{auer2002using}{{6}{2002a}{{Auer}}{{}}}
\bibcite{bang2005doubly}{{7}{2005}{{Bang and Robins}}{{}}}
\bibcite{bastani2021mostly}{{8}{2021}{{Bastani et~al.}}{{Bastani, Bayati, and Khosravi}}}
\bibcite{bishop1995training}{{9}{1995}{{Bishop}}{{}}}
\bibcite{bouneffouf2020survey}{{10}{2020}{{Bouneffouf et~al.}}{{Bouneffouf, Rish, and Aggarwal}}}
\bibcite{buhlmann2011statistics}{{11}{2011}{{B{\"u}hlmann and Van De~Geer}}{{}}}
\bibcite{chapelle2011}{{12}{2011}{{Chapelle and Li}}{{}}}
\bibcite{chu2011contextual}{{13}{2011}{{Chu et~al.}}{{Chu, Li, Reyzin, and Schapire}}}
\bibcite{dani2008stochastic}{{14}{2008}{{Dani et~al.}}{{Dani, Hayes, and Kakade}}}
\bibcite{dimakopoulou2019balanced}{{15}{2019}{{Dimakopoulou et~al.}}{{Dimakopoulou, Zhou, Athey, and Imbens}}}
\bibcite{ferreira2018online}{{16}{2018}{{Ferreira et~al.}}{{Ferreira, Simchi-Levi, and Wang}}}
\bibcite{guttorp2009karl}{{17}{2009}{{Guttorp and Lindgren}}{{}}}
\bibcite{hamidi2019worst}{{18}{2019}{{Hamidi and Bayati}}{{}}}
\bibcite{hsu2020recommending}{{19}{2020}{{Hsu et~al.}}{{Hsu, Tseng, Hsieh, Chang, and Chen}}}
\bibcite{huix2023tight}{{20}{2023}{{Huix et~al.}}{{Huix, Zhang, and Durmus}}}
\bibcite{kim2019doubly}{{21}{2019}{{Kim and Paik}}{{}}}
\bibcite{kim2021doubly}{{22}{2021}{{Kim et~al.}}{{Kim, Kim, and Paik}}}
\bibcite{kim2023double}{{23}{2023{a}}{{Kim et~al.}}{{Kim, Lee, and Paik}}}
\bibcite{kim2023squeeze}{{24}{2023{b}}{{Kim et~al.}}{{Kim, Paik, and Oh}}}
\bibcite{kim2025learning}{{25}{2025}{{Kim et~al.}}{{Kim, Iyengar, and Zeevi}}}
\bibcite{perturb20akveton}{{26}{2020}{{Kveton et~al.}}{{Kveton, Szepesv{\'{a}}ri, Ghavamzadeh, and Boutilier}}}
\bibcite{kveton2021metats}{{27}{2021}{{Kveton et~al.}}{{Kveton, Konobeev, Zhao, Hong, Cheng, and Ahmed}}}
\bibcite{lai1985asymptotically}{{28}{1985}{{Lai and Robbins}}{{}}}
\bibcite{lattimore2020bandit}{{29}{2020}{{Lattimore and Szepesv{\'a}ri}}{{}}}
\bibcite{mockus2005bayesian}{{30}{2005}{{Mockus}}{{}}}
\bibcite{murphy2005experimental}{{31}{2005}{{Murphy}}{{}}}
\bibcite{offer2021adaptive}{{32}{2021}{{Offer-Westort et~al.}}{{Offer-Westort, Coppock, and Green}}}
\bibcite{riou2023matching}{{33}{2023}{{Riou et~al.}}{{Riou, Honda, and Matsushima}}}
\bibcite{rusmevichientong2010linearly}{{34}{2010}{{Rusmevichientong and Tsitsiklis}}{{}}}
\bibcite{satyal2018ab}{{35}{2018}{{Satyal et~al.}}{{Satyal, Weber, Paik, Di~Ciccio, and Mendling}}}
\bibcite{smith1918standard}{{36}{1918}{{Smith}}{{}}}
\bibcite{soare2014best}{{37}{2014}{{Soare et~al.}}{{Soare, Lazaric, and Munos}}}
\bibcite{tao2018best}{{38}{2018}{{Tao et~al.}}{{Tao, Blanco, and Zhou}}}
\bibcite{tropp2012user}{{39}{2012}{{Tropp}}{{}}}
\bibcite{tropp2015introduction}{{40}{2015}{{Tropp}}{{}}}
\bibcite{xu2020upper}{{41}{2020}{{Xu and Zeevi}}{{}}}
\bibcite{zhu2020thompson}{{42}{2020}{{Zhu and Tan}}{{}}}
\newlabel{LastPage}{{B.2}{37}{}{page.37}{}}
\gdef\lastpage@lastpage{37}
\gdef\lastpage@lastpageHy{37}
\gdef \@abspage@last{37}
